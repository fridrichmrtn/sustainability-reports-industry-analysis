{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import magic\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "\n",
    "class DataIngestion():\n",
    "    \n",
    "    def __init__(self,\n",
    "                docs_file = \"../../data/unglobalcompact.csv\",\n",
    "                raw_folder = \"../../data/raw_files/\") -> None:\n",
    "        self.docs_file = docs_file\n",
    "        self.raw_folder = raw_folder\n",
    "        pass\n",
    "\n",
    "    def _sanitize_name(self, name):\n",
    "        name = re.sub(r\"[^a-zA-Z ]\",\"\", name).lower()\n",
    "        return re.sub(r\"[ ]+\", \"_\", name)\n",
    "    \n",
    "    def _get_file_atts(self, path):\n",
    "        dir = os.path.dirname(path)\n",
    "        base_name = os.path.basename(path)\n",
    "        name, extension = os.path.splitext(base_name)\n",
    "        return {\"dir\" : dir,\n",
    "                \"name\" : name,\n",
    "                \"ext\" : extension.split(\"?\")[0]}\n",
    "    \n",
    "    def _get_destination(self, row, dir=None):\n",
    "        atts_dict = self._get_file_atts(row[\"communication_on_progress_file\"])\n",
    "        index = str(row.name)\n",
    "        company =self._sanitize_name(row[\"name\"])\n",
    "        ext = atts_dict[\"ext\"]\n",
    "        if dir is None:\n",
    "            dir = \"\"\n",
    "        return dir + \"_\".join([index, company]) + ext\n",
    "    \n",
    "    def load_docs(self):\n",
    "        self.docs_data = pd.read_csv(self.docs_file)   \n",
    "        new_columns = {c: self._sanitize_name(c) for c in self.docs_data.columns}\n",
    "        self.docs_data = self.docs_data.rename(columns=new_columns)\n",
    "        url_rows = self.docs_data.communication_on_progress_file.notnull()\n",
    "        self.docs_data = self.docs_data.loc[url_rows,\n",
    "                [\"name\",\"type\", \"country\", \"sector\", \"communication_on_progress_file\"]]\n",
    "        self.docs_data[\"file_destination\"] = self.docs_data\\\n",
    "            .apply(self._get_destination, dir=self.raw_folder, axis=1)\n",
    "        return self\n",
    "        \n",
    "    def _download_file(self, url, file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"File on '{file_path}' already exists. Skipping download.\")\n",
    "            return None\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(file_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            print(f\"File on '{file_path}' downloaded successfully.\")\n",
    "            return file_path\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error downloading '{file_path}': {e}.\")\n",
    "            return None\n",
    "\n",
    "    def download_reports(self):\n",
    "        url_list = self.docs_data[\"communication_on_progress_file\"].values\n",
    "        path_list = self.docs_data[\"file_destination\"].values\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            executor.map(self._download_file, url_list, path_list)\n",
    "        return self\n",
    "    \n",
    "    def _check_path(self,path):\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _get_conversion_path(self,file_destination, dir_name=None):\n",
    "        if dir_name==None:\n",
    "            dir_name = os.path.dirname(file_destination)\n",
    "        base_name = os.path.basename(file_destination)\n",
    "        name, extension = os.path.splitext(base_name)\n",
    "        return os.path.join(*[dir_name, name+\".pdf\"])\n",
    "\n",
    "    def _get_metadata(self):\n",
    "        self.docs_data[\"file_type\"] = self.docs_data\\\n",
    "            .apply(lambda x:magic.from_file(x[\"file_destination\"],mime=True), axis=1)\n",
    "        self.docs_data[\"file_size\"] = self.docs_data\\\n",
    "            .apply(lambda x:os.path.getsize(x[\"file_destination\"])/10**6, axis=1)\n",
    "        self.docs_data[\"converted_file_destination\"] = None\n",
    "        pdf_rows = self.docs_data.file_type==\"application/pdf\"\n",
    "        self.docs_data.loc[pdf_rows, \"converted_file_destination\"] = self.docs_data.loc[pdf_rows, \"file_destination\"]\n",
    "        conv_rows_ind = self.docs_data.loc[\n",
    "            (self.docs_data.converted_file_destination.isnull())\n",
    "            & (~self.docs_data.file_type.isin([\"inode/x-empty\", \"application/octet-stream\"]))\n",
    "            & (self.docs_data.file_size<90),].index\n",
    "        self.docs_data[\"conversion\"] = False\n",
    "        self.docs_data.loc[conv_rows_ind, \"conversion\"] = True\n",
    "        return self\n",
    "\n",
    "    def _convert_row(self, ind):\n",
    "        file_destination = self.docs_data.loc[ind, \"file_destination\"]\n",
    "        converted_file_destination = self._get_conversion_path(file_destination)\n",
    "        converted_file_dir = os.path.dirname(converted_file_destination)\n",
    "        # NOTE: make sure this works\n",
    "        if os.path.exists(converted_file_destination):\n",
    "            print(f\"File on '{converted_file_destination}' already exists. Skipping conversion.\")\n",
    "            self.docs_data.loc[ind, \"converted_file_destination\"] = converted_file_destination\n",
    "            return self\n",
    "        try:\n",
    "            cmd = f\"libreoffice --headless --convert-to pdf {file_destination} --outdir {converted_file_dir}\"\n",
    "            status = \" \".join(os.popen(cmd).readlines())\n",
    "            if \"error\" in status.lower():\n",
    "                raise Exception(status)\n",
    "            self.docs_data.loc[ind, \"converted_file_destination\"] = self._check_path(converted_file_destination)\n",
    "            print(f\"File on '{converted_file_destination}' converted successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting '{file_destination}': {e}.\")\n",
    "        return self\n",
    "\n",
    "    def convert_reports(self):\n",
    "        self = self._get_metadata()\n",
    "        for ind in self.docs_data.loc[self.docs_data.conversion,].index:\n",
    "            self = self._convert_row(ind)\n",
    "        return self\n",
    "\n",
    "    # NOTE: use ghostscript, parallelize (it is working, but it is slow)\n",
    "\n",
    "    def _pdf2txt(self, file_path):\n",
    "        pages = pdf2image.convert_from_path(file_path, dpi=200, thread_count=4)\n",
    "        txt = \"\"\n",
    "        for pageNum,imgBlob in enumerate(pages):\n",
    "            txt += pytesseract.image_to_string(imgBlob)\n",
    "        return txt\n",
    "\n",
    "    def _get_txt_path(self, file_path,\n",
    "            dir_name=\"../../data/txt_files/\"):\n",
    "        base_name = os.path.basename(file_path)\n",
    "        name, extension = os.path.splitext(base_name)\n",
    "        return os.path.join(*[dir_name, name+\".txt\"])\n",
    "\n",
    "    def _txt2file(self, text, file_path):\n",
    "        dir = os.path.dirname(file_path)\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        with open(file_path, \"w\") as text_file:\n",
    "            text_file.write(text)\n",
    "        return None\n",
    "\n",
    "    def read_reports(self, overwrite=False):\n",
    "        self.docs_data[\"txt_file_destination\"] = None\n",
    "        for ind, row in self.docs_data.iterrows():\n",
    "            pdf_path = row[\"converted_file_destination\"]\n",
    "            txt_path = self._get_txt_path(pdf_path)\n",
    "            if os.path.exists(txt_path) and not overwrite:\n",
    "                print(f\"File on '{txt_path}' already exists. Skipping reading.\")\n",
    "                self.docs_data.loc[ind, \"txt_file_destination\"] = txt_path\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Reading '{row['converted_file_destination']}'.\")\n",
    "                try:\n",
    "                    txt = self._pdf2txt(pdf_path)\n",
    "                    self._txt2file(txt, txt_path)\n",
    "                    self.docs_data.loc[ind, \"txt_file_destination\"] = self._check_path(txt_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading '{pdf_path}': {e}.\")\n",
    "        return self        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ingest = DataIngestion().load_docs().download_reports().convert_reports().read_reports()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
